{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "98urfbXatqQe"
      },
      "outputs": [],
      "source": [
        "# 17.09.2023 Mikhail Porokhnya\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "UjaZUAm4uP36"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm_PTfTauRy8",
        "outputId": "8280a340-1c47-4058-b32a-2c5535289833"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark"
      ],
      "metadata": {
        "id": "mP-OplCDuTCe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.init('spark-3.5.0-bin-hadoop3')"
      ],
      "metadata": {
        "id": "XldUMOJ7uUcD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode\n",
        "\n",
        "# creating SparkSession\n",
        "spark = SparkSession.builder.appName(\"ProductCategory\").getOrCreate()\n",
        "\n",
        "# example DataFrame with data\n",
        "data = [(\"Product1\", [\"Category1\", \"Category2\"]),\n",
        "        (\"Product2\", [\"Category2\", \"Category3\"]),\n",
        "        (\"Product3\", [])]\n",
        "\n",
        "schema = [\"Product_name\", \"Categories\"]\n",
        "\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# split the list of categories into separate lines\n",
        "df_exploded = df.select(col(\"Product_name\"), explode(col(\"Categories\")).alias(\"Categories\"))\n",
        "\n",
        "# cast to one data type\n",
        "df_exploded = df_exploded.withColumn(\"Categories\", df_exploded[\"Categories\"].cast(\"string\"))\n",
        "\n",
        "# create a DataFrame with products without categories\n",
        "df_with_empty_categories = df.filter((col(\"Categories\").cast(\"string\") == \"[]\"))\n",
        "\n",
        "# cast to one data type\n",
        "df_with_empty_categories = df_with_empty_categories.withColumn(\"Categories\", df_with_empty_categories[\"Categories\"].cast(\"string\"))\n",
        "\n",
        "# merging two DataFrames\n",
        "result_df = df_exploded.union(df_with_empty_categories)\n",
        "\n",
        "# display the result\n",
        "result_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoH7OrBVuWlP",
        "outputId": "bf4411de-4f9d-47b7-9b60-aa1db83a5bd7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+\n",
            "|Product_name|Categories|\n",
            "+------------+----------+\n",
            "|    Product1| Category1|\n",
            "|    Product1| Category2|\n",
            "|    Product2| Category2|\n",
            "|    Product2| Category3|\n",
            "|    Product3|        []|\n",
            "+------------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}